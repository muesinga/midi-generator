{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generation of music midi files with a probabilistic generative model\n",
    "Sebastián García Valencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "A particular kind of machine learning model with the capacity to generate information is known as a generative model. There are many variations, but all they focus on learning patterns in a dataset to then produce data with a given seed.\n",
    "\n",
    "In this case, I will use a very simple generative probabilistic model called n-gram to generate midi sequences of music.\n",
    "\n",
    "### Markov Chain\n",
    "A Markov chain is a model that predicts the next event in a sequence based only on the present event, \"forgetting\" all the previous states.\n",
    "\n",
    "### N-gram Model\n",
    "An N-gram model is a probabilistic generative model which predicts the next sample in a sequence based on the previous n-1 samples. formaly\n",
    "\n",
    "$$P(x_i | x_{i-(n-1)}, ..., x_{i-1})$$\n",
    "\n",
    "It achieves this creating the n-grams for the input data, which consists of all the possible n-tuple of contiguous elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "In my implementation of the model (in this case a for n=3, also known as trigram), the basic idea is to create prefixes and suffixes. Notice that I don't have an exception for the case that the suffix is already in the dictionary for a given key (prefix). I insert it multiple times on purpose, this the most straightforward way of achieving the probabilistic feature of the model. In the end, this dictionary of the prefixes with all the suffixes will be our trained model. The decision of use as corpus a list of strings is due to the ease to manipulate them and use them as key in dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# create a dict with the ngram model, it receives a list with the samples as string\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "# create a dict with the ngram model, it receives a list with the samples as string\n",
    "ngram_dict = {}\n",
    "\n",
    "def create_trigram_dict(corpus):\n",
    "    n = 3\n",
    "    ngrams = nltk.ngrams(corpus, n)\n",
    "    \n",
    "    for grams in ngrams:\n",
    "        dict_key = grams[:-1][0] + \" \" + grams[:-1][1]\n",
    "        if dict_key in ngram_dict:\n",
    "            ngram_dict[dict_key].append(grams[-1])\n",
    "        else:\n",
    "            ngram_dict[dict_key] = []\n",
    "            ngram_dict[dict_key].append(grams[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sequence, it is necessary to use as seed an existent prefix in the model (this a disadvantage of n-grams models), then it will select one of the suffixes randomly, update the seed (deleting the first sample and inserting the new one) and begin the process again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigram(seed, samples = 15):\n",
    "    output = seed  \n",
    "    for i in range(samples):\n",
    "        # When it reaches the last prefix, there is no suffix, so end\n",
    "        try:\n",
    "            new_sample = random.choice(ngram_dict[seed])\n",
    "        except:\n",
    "            return output\n",
    "        output += \" \" + new_sample\n",
    "        seed = seed.split(\" \")[1] + \" \" + new_sample\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'... maybe': ['I'],\n",
       " 'I a': ['gram', 'markov', 'gram'],\n",
       " 'I am': ['both'],\n",
       " 'a gram': ['or', 'only'],\n",
       " 'a markov': ['chain'],\n",
       " 'am I': ['a', 'a', 'a'],\n",
       " 'chain am': ['I'],\n",
       " 'gram only': ['...'],\n",
       " 'gram or': ['am'],\n",
       " 'markov chain': ['am'],\n",
       " 'maybe I': ['am'],\n",
       " 'only ...': ['maybe'],\n",
       " 'or am': ['I']}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_corpus = 'am I a gram or am I a markov chain am I a gram only ... maybe I am both'\n",
    "ngram_dict = {}\n",
    "create_trigram_dict(word_corpus.split(\" \"))\n",
    "ngram_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example, the sentence 'am I a gram or am I a Markov chain am I a gram only ... maybe I am both' is used as the dataset. As you can see in the dictionary, the prefix 'I a' has 3 suffixes: 'gram', 'Markov' and 'gram' again. Here is the importance of insert repetitions, when you make a random choice over this list, 'gram' has a 66.6% of probability of being chosen, without the necessity of calculating this numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am I a gram or am I a gram or am I a gram only ... maybe I am both\n"
     ]
    }
   ],
   "source": [
    "print generate_trigram(\"am I\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am I a markov chain am I a markov chain am I a gram or am I a gram or am I a gram or am I a gram only ... maybe\n"
     ]
    }
   ],
   "source": [
    "print generate_trigram(\"am I\", 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "markov chain am I a gram or am I a gram or am I a gram only ... maybe I am both\n"
     ]
    }
   ],
   "source": [
    "print generate_trigram(\"markov chain\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Music Dataset\n",
    "\n",
    "To use the model as music generator, we will use a set of midi sequences. The starting point is the mono-MusicXML-dataset (https://github.com/EelcovdW/mono-MusicXML-dataset), this consists of 3 lists of keys (train, evaluation and validation) for monophonic songs in musescore, a repository for music sheet.\n",
    "\n",
    "The procedure was to use these keys to download the songs in midi format. Then, I applied a series of cleaning and transformations to obtain an X and a Y array composed entirely by the integers representing the midi notes, focusing only in the sequence of notes and ignoring all the other features (time, tempo, etc.). The X corresponds to all the songs concatenated without the last element of each song, the Y to the same, but without the first note of each song, this can be used for an X -> Y type machine learning model.\n",
    "\n",
    "![Dataset workflow](datasetflow.png)\n",
    "\n",
    "For the case of this n-gram model, the data will be the x array of the validation dataset (around 2400 songs before transformations). To have more data, I applied a strategy of data augmentation, this usually done in computer vision, to generate a more significant dataset of images by rotating and translating the existent one. In this case, I transposed each song to have a version of it with each possible note as key note depending on how far is the song from central C and trying to spread the song the best possible through the midi range (0-127). The pseudo of this process is:\n",
    "\n",
    "![Dataset pseudocode](datasetPseudocode.png)\n",
    "\n",
    "I provide the final dataset as a pickle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and model creation\n",
    "Let's load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!!!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "midi_dataset = pickle.load(open(\"validation_DB12_final_cleaned.p\", \"rb\"))\n",
    "print(\"ready!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasnform it to a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = midi_dataset[\"x\"]\n",
    "corpus_str=map(str, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the model and generate a song using C4 D4 as seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!!!\n"
     ]
    }
   ],
   "source": [
    "ngram_dict = {}\n",
    "create_trigram_dict(corpus_str)\n",
    "print(\"ready!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 62 60 58 55 51 53 56 55 53 53 53 53 53 55 56 58 60 58 60 55 60 55 56 60 60 60 63 63 63 65 68 65 65 50 58 57 55 57 60 69 67\n"
     ]
    }
   ],
   "source": [
    "generated_melody = generate_trigram(\"60 62\", 40)\n",
    "print(generated_melody)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can export the sequence as a midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midiutil.MidiFile import MIDIFile   \n",
    "\n",
    "# takes a list of integers representing midi notes and creates a .mid\n",
    "# with a contant time of a quarter note for all the notes and 120 \n",
    "# as tempo(taken from garcia, 2018)\n",
    "def sequenceVector2midiMelody(seqVector, file_dir):\n",
    "    MyMIDI = MIDIFile(1)\n",
    "    track = 0 \n",
    "    time = 0\n",
    "    MyMIDI.addTrackName(track,time,\"Sample Track\") \n",
    "    MyMIDI.addTempo(track,time,120)\n",
    "    time = 0\n",
    "    for note in seqVector:\n",
    "        # MyMIDI.addNote(track,channel,pitch,time,duration,volume)\n",
    "        MyMIDI.addNote(0,0,note,time,1,100)\n",
    "        time = time + 1\n",
    "\n",
    "    binfile = open(file_dir, 'wb') \n",
    "    MyMIDI.writeFile(binfile) \n",
    "    binfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceVector2midiMelody(map(int,generated_melody.split(\" \")), 'generated_melody.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and listen to the midi\n",
    "For the next part is necessary to have the musescore software installed, you can do it with the command sudo apt-get install musescore, and then replace the uri in the 2 lines of environment, it will usually be: \"/usr/bin/musescore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi\n",
    "import music21\n",
    "music21.environment.set(\"musicxmlPath\", \"/usr/bin/musescore\")\n",
    "music21.environment.set('musescoreDirectPNGPath', '/usr/bin/musescore')\n",
    "\n",
    "mid_file = midi.MidiFile()\n",
    "mid_file.open(\"generated_melody.mid\")\n",
    "mid_file.read()\n",
    "mid_file.close()\n",
    "mid_stream = midi.translate.midiFileToStream(mid_file)\n",
    "mid_stream.show()\n",
    "\n",
    "print(\"Playing midi file .................\")\n",
    "sp = midi.realtime.StreamPlayer(mid_stream)\n",
    "sp.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizing to n-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easily we can generalize from the trigram above to an n-gram model, the larger the selected n the more context it will have into account, the disadventage is the necesity of using a seed that exist in the model, the larger the n, the difficult to find one. To see models without this weakness see my paper on music composition with Recurrent Neural Networks (right now it is in publishing proccess, as soon as it is available I will share it here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "# create a dict with the ngram model, it receives a list with the samples as string, an the n pramater\n",
    "# of the n-gram\n",
    "ngram_dict = {}\n",
    "\n",
    "def create_ngram_dict(corpus, n = 3):\n",
    "    ngrams = nltk.ngrams(corpus, n)\n",
    "    \n",
    "    for grams in ngrams:\n",
    "        dict_key = grams[:-1][0] \n",
    "        for i in range(1, n-1):\n",
    "             dict_key += \" \" + grams[:-1][i]\n",
    "        if dict_key in ngram_dict:\n",
    "            ngram_dict[dict_key].append(grams[-1])\n",
    "        else:\n",
    "            ngram_dict[dict_key] = []\n",
    "            ngram_dict[dict_key].append(grams[-1])\n",
    "            \n",
    "def generate_ngram(seed, samples = 15):\n",
    "    output = seed  \n",
    "    for i in range(samples):\n",
    "        # When it reaches the last prefix, there is no suffix, so end\n",
    "        try:\n",
    "            new_sample = random.choice(ngram_dict[seed])\n",
    "        except:\n",
    "            return output\n",
    "        output += \" \" + new_sample\n",
    "        temp_seed = seed.split(\" \")[1]\n",
    "        #import pdb\n",
    "        #pdb.set_trace()\n",
    "        for sample in seed.split(\" \")[2:]:\n",
    "            temp_seed += \" \" + sample \n",
    "        seed = temp_seed + \" \" + new_sample\n",
    "\n",
    "    return output            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the text example from the beginning, but with n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'... maybe I am': ['both'],\n",
       " 'I a gram only': ['...'],\n",
       " 'I a gram or': ['am'],\n",
       " 'I a markov chain': ['am'],\n",
       " 'a gram only ...': ['maybe'],\n",
       " 'a gram or am': ['I'],\n",
       " 'a markov chain am': ['I'],\n",
       " 'am I a gram': ['or', 'only'],\n",
       " 'am I a markov': ['chain'],\n",
       " 'chain am I a': ['gram'],\n",
       " 'gram only ... maybe': ['I'],\n",
       " 'gram or am I': ['a'],\n",
       " 'markov chain am I': ['a'],\n",
       " 'only ... maybe I': ['am'],\n",
       " 'or am I a': ['markov']}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_corpus = 'am I a gram or am I a markov chain am I a gram only ... maybe I am both'\n",
    "ngram_dict = {}\n",
    "create_ngram_dict(word_corpus.split(\" \"), 5)\n",
    "ngram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I a gram or am I a markov chain am I a gram only ... maybe I am both\n"
     ]
    }
   ],
   "source": [
    "print generate_ngram(\"I a gram or\", 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's generate a music sequence using as seed the first sequence of notes of the major C scale, starting in central C (C4 D4 E4 F4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!!!\n"
     ]
    }
   ],
   "source": [
    "ngram_dict = {}\n",
    "create_ngram_dict(corpus_str, 5)\n",
    "print(\"ready!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 62 64 65 67 67 65 67 69 71 72 74 76 76 74 71 72 74 76 77 77 74 76 74 72 82 81 73 74 77 81 79 76 73 69 67 64 67 69 73 76 79 82 69\n"
     ]
    }
   ],
   "source": [
    "generated_melody = generate_ngram(\"60 62 64 65\", 40)\n",
    "print(generated_melody)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://golang.org/doc/codewalk/markov/\n",
    "\n",
    "https://en.wikipedia.org/wiki/Markov_chain\n",
    "\n",
    "https://en.wikipedia.org/wiki/N-gram#n-gram_models\n",
    "\n",
    "https://github.com/EelcovdW/mono-MusicXML-dataset\n",
    "\n",
    "https://musescore.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "88c527529a0899dd98bb39d55914dba82853b3c64de3408f7e02c6006e822a98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
